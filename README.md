# llmos-lite: Browser-Native Computational Workbench

> Build, execute, and share computational workflows entirely in your browser

[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/EvolvingAgentsLabs/llmos/releases)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.10+-yellow.svg)](https://python.org)
[![React](https://img.shields.io/badge/react-18+-61dafb.svg)](https://reactjs.org)

---

## ğŸš€ What is llmos-lite?

**llmos-lite** is a modern web application for building and executing computational workflows directly in the browser. No servers required for executionâ€”everything runs client-side via WebAssembly.

### Core Concepts

1. **Skills** - Reusable computational units stored as Markdown files
2. **Workflows** - Visual DAGs built with drag-and-drop React Flow interface
3. **Browser Execution** - WebAssembly runtimes (Pyodide, Three.js, SPICE)
4. **Production Storage** - Vercel Blob + Redis for persistence
5. **LLM Integration** - Chat interface with skill-aware context

### Key Features

- âš¡ **Zero-latency execution** - Skills run instantly via WebAssembly
- ğŸ¨ **Rich previews** - 3D graphics, charts, quantum circuits
- ğŸ”’ **Sandboxed & safe** - Code executes in browser, not servers
- ğŸ’° **Zero server costs** - Computation on user devices
- ğŸ“¦ **Production-ready** - Redis + Blob storage with graceful fallbacks
- ğŸ¤– **LLM-powered** - Chat via OpenRouter (100+ models, free tier available)

---

## Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/EvolvingAgentsLabs/llmos.git
cd llmos

# Install Python dependencies (API)
pip install -r requirements.txt

# Install Node.js dependencies (UI)
cd llmos-lite/ui
npm install
```

### 2. Environment Setup

Create a `.env` file in the root directory:

```bash
# Required: OpenRouter API key for LLM chat
# Get your free API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-xxx...

# Optional: Vercel Blob storage (for skills/files)
# BLOB_READ_WRITE_TOKEN=vercel_blob_rw_xxx...

# Optional: Redis storage (for sessions/messages)
# REDIS_URL=redis://default:password@host:port
```

**Note:**
- `.env` is gitignored and will never be committed
- OpenRouter gives you access to 100+ models including Claude, GPT-4, and free models
- Get your free API key at https://openrouter.ai/keys
- Browse all free models: https://openrouter.ai/models/?q=free

**ğŸ’¡ Recommended Models:**

**Free Models:**
- `tng/deepseek-r1t2-chimera:free` - DeepSeek R1T2 Chimera (reasoning model)

**Premium Models (Paid):**
- `anthropic/claude-opus-4.5` - Claude Opus 4.5 (best quality)
- `openai/gpt-5.2` - GPT-5.2 (latest from OpenAI)

[View all free models â†’](https://openrouter.ai/models/?q=free)

### 3. Run the App

```bash
# Terminal 1: Start FastAPI backend
cd llmos-lite
python api/main.py
# â†’ http://localhost:8000

# Terminal 2: Start Next.js frontend
cd llmos-lite/ui
npm run dev
# â†’ http://localhost:3000
```

### 4. Test the API

```bash
# Chat with computational skills
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $OPENROUTER_API_KEY" \
  -d '{
    "user_id": "alice",
    "team_id": "engineering",
    "message": "Create a quantum VQE circuit",
    "include_skills": true,
    "model": "anthropic/claude-3.5-sonnet"
  }'

# Create a session
curl -X POST "http://localhost:8000/api/sessions" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Quantum Research",
    "volume": "user",
    "initial_message": "Hello!"
  }'
```

---

## Storage Setup

### Local Development (Mock Data)

By default, llmos-lite works with mock data. No storage setup required for testing!

### Production Storage (Vercel)

For production deployments:

#### Vercel Blob (Skills & Files)

1. Go to [Vercel Dashboard](https://vercel.com/dashboard)
2. Select project â†’ **Storage** â†’ **Create Database** â†’ **Blob**
3. Name: `llmos-files`
4. Copy `BLOB_READ_WRITE_TOKEN`
5. Add to `.env` and Vercel environment variables

#### Redis (Sessions & Messages)

1. Vercel dashboard â†’ **Storage** â†’ **Create Database** â†’ **Redis**
2. Copy `REDIS_URL`
3. Add to `.env` and Vercel environment variables

#### Deploy

```bash
npm install -g vercel
vercel --prod
# Your app is live! ğŸ‰
```

---

## Architecture

### System Overview

```mermaid
graph TB
    subgraph Browser["ğŸŒ PRESENTATION LAYER (Browser)"]
        ReactFlow["âš¡ React Flow<br/>Canvas"]
        Chat["ğŸ’¬ Chat Interface<br/>(Skill Context)"]
    end

    subgraph Execution["âš™ï¸ EXECUTION LAYER"]
        Executor["ğŸ”§ Workflow Executor<br/>(TypeScript/Wasm)"]
        SkillMgr["ğŸ“š Skills Manager<br/>(Load/Filter)"]
    end

    subgraph API["ğŸ”Œ INTERFACE LAYER (FastAPI)"]
        Sessions["ğŸ“ /api/sessions<br/>(persistence)"]
        Skills["ğŸ¯ /api/skills<br/>(storage)"]
        ChatAPI["ğŸ¤– /chat<br/>(LLM + context)"]
    end

    subgraph Storage["ğŸ’¾ STORAGE LAYER"]
        Redis["ğŸ”´ Redis<br/>Sessions + Messages"]
        Blob["ğŸ“¦ Vercel Blob<br/>Skills + Files"]
        Git["ğŸ“‚ Git<br/>(future)"]
    end

    ReactFlow --> Executor
    Chat --> SkillMgr
    Executor --> Sessions
    Executor --> Skills
    SkillMgr --> ChatAPI
    Sessions --> Redis
    Skills --> Blob
    ChatAPI --> Blob

    style Browser fill:#1a1a2e,stroke:#00ff00,stroke-width:2px,color:#00ff00
    style Execution fill:#16213e,stroke:#00d9ff,stroke-width:2px,color:#00d9ff
    style API fill:#0f3460,stroke:#ff8800,stroke-width:2px,color:#ff8800
    style Storage fill:#1a1a1a,stroke:#ff0080,stroke-width:2px,color:#ff0080

    style ReactFlow fill:#2d4a3e,stroke:#00ff00,color:#00ff00
    style Chat fill:#2d4a3e,stroke:#00ff00,color:#00ff00
    style Executor fill:#2d3e4a,stroke:#00d9ff,color:#00d9ff
    style SkillMgr fill:#2d3e4a,stroke:#00d9ff,color:#00d9ff
    style Sessions fill:#3e2d4a,stroke:#ff8800,color:#ff8800
    style Skills fill:#3e2d4a,stroke:#ff8800,color:#ff8800
    style ChatAPI fill:#3e2d4a,stroke:#ff8800,color:#ff8800
    style Redis fill:#4a2d2d,stroke:#ff0080,color:#ff0080
    style Blob fill:#4a2d2d,stroke:#ff0080,color:#ff0080
    style Git fill:#4a2d2d,stroke:#ff0080,color:#ff0080
```

### Storage Architecture

```mermaid
graph LR
    subgraph Redis["ğŸ”´ Redis (Sessions & Metadata)"]
        S1["session:{id}<br/>â†’ Session JSON"]
        S2["session:{id}:messages<br/>â†’ Message list"]
        S3["{volume}:{id}:sessions<br/>â†’ Session IDs set"]
        S4["all:sessions<br/>â†’ All session IDs"]
    end

    subgraph Blob["ğŸ“¦ Vercel Blob (Skills & Files)"]
        B1["volumes/system/<br/>system/skills/<br/>{skill}.md"]
        B2["volumes/user/<br/>{user_id}/skills/<br/>{skill}.md"]
        B3["volumes/team/<br/>{team_id}/skills/<br/>{skill}.md"]
    end

    style Redis fill:#1a1a1a,stroke:#ff0080,stroke-width:2px,color:#ff0080
    style Blob fill:#1a1a1a,stroke:#00d9ff,stroke-width:2px,color:#00d9ff
    style S1 fill:#2d1a1a,stroke:#ff0080,color:#ff0080
    style S2 fill:#2d1a1a,stroke:#ff0080,color:#ff0080
    style S3 fill:#2d1a1a,stroke:#ff0080,color:#ff0080
    style S4 fill:#2d1a1a,stroke:#ff0080,color:#ff0080
    style B1 fill:#1a2d2d,stroke:#00d9ff,color:#00d9ff
    style B2 fill:#1a2d2d,stroke:#00d9ff,color:#00d9ff
    style B3 fill:#1a2d2d,stroke:#00d9ff,color:#00d9ff
```

For detailed technical documentation, see [ARCHITECTURE.md](ARCHITECTURE.md).

---

## Key Concepts

### 1. Skills (Computational Units)

Skills are version-controlled Markdown files that define reusable computational capabilities.

**Example Skill:**
```markdown
---
name: VQE Optimizer
skill_id: quantum-vqe-node
type: qiskit
category: quantum
execution_mode: browser-wasm
inputs:
  - name: hamiltonian
    type: object
  - name: iterations
    type: number
outputs:
  - name: eigenvalue
    type: number
---

# Skill: VQE Optimizer

Variational Quantum Eigensolver implementation.

\`\`\`python
def execute(inputs):
    # Runs in browser via Pyodide
    from qiskit import QuantumCircuit
    # ... VQE implementation
    return {"eigenvalue": -1.137}
\`\`\`
```

### 2. Workflows (Visual DAGs)

Drag-and-drop computational graphs built with React Flow.

**Example Workflow:**

```mermaid
graph LR
    H["âš›ï¸ Hamiltonian<br/>Builder"] --> V["ğŸ”¬ VQE<br/>Optimizer"]
    V --> P["ğŸ“Š Plot<br/>Convergence"]
    P --> E["ğŸ’¾ Export<br/>Results"]

    style H fill:#2d4a3e,stroke:#00ff00,stroke-width:2px,color:#00ff00
    style V fill:#3e2d4a,stroke:#ff0080,stroke-width:2px,color:#ff0080
    style P fill:#2d3e4a,stroke:#00d9ff,stroke-width:2px,color:#00d9ff
    style E fill:#4a3e2d,stroke:#ff8800,stroke-width:2px,color:#ff8800
```

Each node executes in the browser via WebAssembly.

### 3. Sessions (Chat History)

Sessions store conversations with:
- Messages (user + assistant)
- Execution traces
- Artifacts (generated files)
- Volume-scoped access (user/team/system)

### 4. Volumes (Multi-Tenant Storage)

```mermaid
graph TD
    Root["ğŸ“ /volumes/"]
    System["ğŸŒ system/<br/>(Global skills)"]
    Team["ğŸ‘¥ team/{team_id}/<br/>(Shared skills)"]
    User["ğŸ‘¤ user/{user_id}/<br/>(Private skills)"]

    Root --> System
    Root --> Team
    Root --> User

    System --> SRead["âœ… Users: Read Only"]
    Team --> TRead["âœ… Users: Read Only<br/>âœ… Team: Read/Write"]
    User --> UWrite["âœ… User: Read/Write"]

    style Root fill:#1a1a1a,stroke:#ffffff,stroke-width:2px,color:#ffffff
    style System fill:#2d4a3e,stroke:#00ff00,stroke-width:2px,color:#00ff00
    style Team fill:#3e2d4a,stroke:#ff0080,stroke-width:2px,color:#ff0080
    style User fill:#2d3e4a,stroke:#00d9ff,stroke-width:2px,color:#00d9ff
    style SRead fill:#1a2d1a,stroke:#00ff00,color:#00ff00
    style TRead fill:#2d1a2d,stroke:#ff0080,color:#ff0080
    style UWrite fill:#1a2d2d,stroke:#00d9ff,color:#00d9ff
```

---

## API Endpoints

### Sessions
- `GET /api/sessions` - List sessions
- `GET /api/sessions/{id}` - Get session
- `POST /api/sessions` - Create session
- `POST /api/sessions/{id}/messages` - Add message
- `PUT /api/sessions/{id}` - Update session
- `DELETE /api/sessions/{id}` - Delete session

### Skills
- `GET /api/skills` - List skills
- `GET /api/skills/{id}` - Get skill
- `POST /api/skills` - Create skill
- `DELETE /api/skills/{id}` - Delete skill

### Chat
- `POST /chat` - Chat with LLM via OpenRouter (includes skills as context)
  - Headers: `X-API-Key` (your OpenRouter key), `X-Model` (optional model override)
  - Supports 100+ models: Claude, GPT-4, Gemini, Llama, and free models

### Workflows
- `GET /workflows/skills/executable` - List executable skills
- `POST /workflows/execute` - Prepare workflow execution
- `POST /workflows/save` - Save workflow
- `GET /workflows/categories` - List categories

---

## Features

### Completed âœ…

1. **React Flow Canvas**
   - Drag-drop node positioning
   - Custom SkillNode components
   - MiniMap for navigation
   - Zoom controls + background grid
   - Run workflow button

2. **Node Library Panel**
   - 8 pre-loaded skills (Quantum, 3D, Electronics, Data, Code)
   - Category filtering
   - Search functionality
   - Draggable skill cards

3. **Storage Integration**
   - Redis client for sessions/messages
   - Blob client for skills/files
   - Graceful fallbacks to mock data

4. **Preview Renderers**
   - PlotRenderer (line, scatter, bar charts via Recharts)
   - ThreeRenderer (3D visualizations via Three.js + WebGL)
   - CircuitRenderer (quantum circuit diagrams via SVG)

### Next Steps ğŸš§

- [x] Drag-drop from library â†’ canvas âœ…
- [x] Workflow execution integration âœ…
- [ ] Real-time collaboration

---

## Examples

### Quantum VQE Workflow

```mermaid
graph LR
    H["âš›ï¸ Hamiltonian Node<br/>Define quantum system"]
    V["ğŸ”¬ VQE Node<br/>Run simulation (Pyodide)"]
    P["ğŸ“Š Plot Node<br/>Visualize convergence"]
    E["ğŸ’¾ Export Node<br/>Save results"]

    H -->|"Hamiltonian<br/>matrix"| V
    V -->|"Energy values<br/>convergence data"| P
    P -->|"Chart<br/>image"| E

    style H fill:#2d4a3e,stroke:#00ff00,stroke-width:3px,color:#00ff00
    style V fill:#3e2d4a,stroke:#ff0080,stroke-width:3px,color:#ff0080
    style P fill:#2d3e4a,stroke:#00d9ff,stroke-width:3px,color:#00d9ff
    style E fill:#4a3e2d,stroke:#ff8800,stroke-width:3px,color:#ff8800
```

**Result:** âš¡ Instant, interactive execution via WebAssembly

### 3D Animation Workflow

```mermaid
graph LR
    M["ğŸ¨ Model Node<br/>Create 3D geometry"]
    Mat["ğŸ–¼ï¸ Material Node<br/>Apply textures"]
    S["ğŸ¬ Scene Node<br/>Position objects"]
    R["ğŸ® Render Node<br/>WebGL rendering (60 FPS)"]

    M -->|"Geometry<br/>data"| Mat
    Mat -->|"Textured<br/>mesh"| S
    S -->|"Scene<br/>graph"| R

    style M fill:#2d4a3e,stroke:#00ff00,stroke-width:3px,color:#00ff00
    style Mat fill:#4a2d3e,stroke:#ff00ff,stroke-width:3px,color:#ff00ff
    style S fill:#2d3e4a,stroke:#00d9ff,stroke-width:3px,color:#00d9ff
    style R fill:#4a3e2d,stroke:#ff8800,stroke-width:3px,color:#ff8800
```

**Result:** ğŸ¨ Real-time 3D visualization using Three.js

---

## Project Structure

```
llmos-lite/
â”œâ”€â”€ api/                          # FastAPI backend
â”‚   â”œâ”€â”€ main.py                   # Main API server
â”‚   â”œâ”€â”€ sessions.py               # Session endpoints
â”‚   â”œâ”€â”€ skills.py                 # Skill endpoints
â”‚   â”œâ”€â”€ chat.py                   # Chat endpoint
â”‚   â””â”€â”€ lib/                      # Storage clients
â”‚       â”œâ”€â”€ redis_client.py       # Redis adapter
â”‚       â”œâ”€â”€ vercel_kv.py          # Vercel KV client
â”‚       â””â”€â”€ vercel_blob.py        # Blob storage client
â”‚
â””â”€â”€ ui/                           # Next.js frontend
    â”œâ”€â”€ components/
    â”‚   â””â”€â”€ panel3-artifacts/
    â”‚       â”œâ”€â”€ WorkflowCanvas.tsx
    â”‚       â”œâ”€â”€ NodeLibraryPanel.tsx
    â”‚       â”œâ”€â”€ PlotRenderer.tsx
    â”‚       â”œâ”€â”€ ThreeRenderer.tsx
    â”‚       â””â”€â”€ CircuitRenderer.tsx
    â””â”€â”€ lib/
        â”œâ”€â”€ workflow-executor.ts
        â””â”€â”€ pyodide-executor.ts
```

---

## Roadmap

### Phase 1: Core Infrastructure âœ… (Complete)
- [x] FastAPI service
- [x] Skills loader
- [x] Storage clients
- [x] Chat integration

### Phase 2: WebAssembly Workflows âœ… (Complete)
- [x] Executable skill format
- [x] Workflow engine (DAG execution)
- [x] Pyodide integration
- [x] Multi-runtime support

### Phase 3: React UI âœ… (Complete)
- [x] React Flow canvas
- [x] Node library panel
- [x] Drag-drop from library to canvas
- [x] Workflow execution via API
- [x] Execution controls & progress
- [x] Storage integration (Redis + Blob)
- [x] Chat interface
- [x] Preview renderers (plots, 3D, circuits)

### Phase 4: Advanced Features (Future)
- [ ] GPU acceleration (WebGPU)
- [ ] Workflow marketplace
- [ ] Collaborative editing
- [ ] Mobile PWA
- [ ] Auto-generate skills from patterns

---

## Contributing

We welcome contributions!

**Priority areas:**
1. Workflow execution integration
2. New computational skills (quantum, 3D, ML, electronics)
3. Runtime integrations (WebGPU, WebR)
4. Example workflows

**Development workflow:**
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## Security

- âœ… API keys in `.env` (gitignored)
- âœ… Environment variables for secrets
- âœ… No hardcoded credentials
- âœ… Sandboxed WebAssembly execution

**Production checklist:**
- [ ] Rotate API keys
- [ ] Add authentication (JWT/OAuth)
- [ ] Enable CORS restrictions
- [ ] Set up rate limiting

---

## License

Apache 2.0

---

## Credits

Built by [Evolving Agents Labs](https://github.com/EvolvingAgentsLabs)

**Core Innovation:** Version-controlled Markdown skills that execute as WebAssembly workflows in the browser.

Inspired by OpenAI/Anthropic's Skills paradigm for AI capabilities.

---

<div align="center">

**[Architecture](ARCHITECTURE.md)** Â· **[GitHub](https://github.com/EvolvingAgentsLabs/llmos)** Â· **[Issues](https://github.com/EvolvingAgentsLabs/llmos/issues)**

</div>
